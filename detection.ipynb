{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3c5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d.ml as _ml3d\n",
    "import open3d.ml.torch as ml3d\n",
    "\n",
    "framework = 'torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b6f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"kitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90ed7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# download the weights.\n",
    "ckpt_folder = \"./logs/\"\n",
    "os.makedirs(ckpt_folder, exist_ok=True)\n",
    "ckpt_path = ckpt_folder + \"pointpillars_kitti_202012221652utc.pth\"\n",
    "pointpillar_url = \"https://storage.googleapis.com/open3d-releases/model-zoo/pointpillars_kitti_202012221652utc.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d252a51f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_custom_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_custom_dataset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_custom_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_custom_dataset('trainval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = custom_dataset\n",
    "\n",
    "model = ml3d.models.PointPillars(**cfg.model)\n",
    "\n",
    "pipeline = ml3d.pipelines.ObjectDetection(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7a09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d.ml as _ml3d\n",
    "import open3d.ml.torch as ml3d\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3fc100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('trainval/*/*_bbox.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e30e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point clouds and labels to pcd\n",
    "\n",
    "labels = defaultdict(list)\n",
    "for file in files:\n",
    "    \n",
    "    bbox = np.fromfile(file, dtype=np.float32)\n",
    "    labels[bbox[9]].append(file)\n",
    "    \n",
    "    xyz = np.fromfile(file.replace('_bbox.bin', '_cloud.bin'), dtype=np.float32)\n",
    "    xyz = xyz.reshape([3, -1])\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(xyz.T)\n",
    "    \n",
    "    o3d.io.write_point_cloud(file.replace('_bbox.bin', '.pcd'), pcd)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907df864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_dataset():\n",
    "    \n",
    "    pcds = []\n",
    "    \n",
    "    for file in files:\n",
    "        xyz = np.fromfile(file.replace('_bbox.bin', '_cloud.bin'), dtype=np.float32)\n",
    "        xyz = xyz.reshape([3, -1])\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(xyz.T)\n",
    "        pcds.append(pcd)\n",
    "        \n",
    "    return pcds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1f8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"kitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f71b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ml3d.models.PointPillars(**cfg.model, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e98cf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ds = load_custom_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19c98f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ml3d.pipelines.ObjectDetection(model, device=\"cpu\", **cfg.pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f47d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_folder = \"./logs/\"\n",
    "ckpt_path = ckpt_folder + \"pointpillars_kitti_202012221652utc.pth\"\n",
    "\n",
    "pipeline.load_ckpt(ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff6a11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_point_cloud_for_inference(pcd):\n",
    "    # Remove NaNs and infinity values\n",
    "    pcd.remove_non_finite_points()\n",
    "    # Extract the xyz points\n",
    "    xyz = pcd.points\n",
    "\n",
    "    # PointPillars classifier needs a 4th dimension (intensity), which my custom data does not have.\n",
    "    # We add it here with default value of 0.5\n",
    "    xyzi = []\n",
    "    for point in xyz:\n",
    "        xyzi.append(list(point) + [0.5])\n",
    "    xyzi = np.array(xyzi)\n",
    "\n",
    "    # Set the points to the correct format for inference\n",
    "    data = {\"point\":xyzi, 'feat': None, 'label':np.zeros((len(xyz),), dtype=np.int32)}\n",
    "\n",
    "    return data, pcd\n",
    "\n",
    "\n",
    "data, pcd = prepare_point_cloud_for_inference(custom_ds[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2df41412",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'point'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m m \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 16\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/open3d/_ml3d/torch/models/point_pillars.py:131\u001b[0m, in \u001b[0;36mPointPillars.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m--> 131\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint\u001b[49m\n\u001b[1;32m    132\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feats(inputs)\n\u001b[1;32m    133\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'point'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pc = custom_ds[0]\n",
    "\n",
    "data = {\n",
    "    'point': pc,\n",
    "    'full_point': pc,\n",
    "    'feat': None,\n",
    "    'calib': None,\n",
    "    'bounding_boxes': None,\n",
    "}\n",
    "\n",
    "\n",
    "m = pipeline.model\n",
    "with torch.no_grad():\n",
    "    result = m(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52bcd3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'open3d.ml.torch.datasets' has no attribute 'base_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[43mml3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mBaseDataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'open3d.ml.torch.datasets' has no attribute 'base_dataset'"
     ]
    }
   ],
   "source": [
    "base = ml3d.datasets.base_dataset.BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f953a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDS(ml3d.datasets.Custom3D):\n",
    "    def __init__(self, name=\"MYDS\"):\n",
    "        super().__init__(dataset, split=split)\n",
    "        \n",
    "    def get_split(self, split):\n",
    "        return MyDatasetSplit(self, split=split)\n",
    "    \n",
    "    def is_tested(self, attr):\n",
    "        # checks whether attr['name'] is already tested.\n",
    "\n",
    "    def save_test_result(self, results, attr):\n",
    "        # save results['predict_labels'] to file.\n",
    "        return\n",
    "    \n",
    "    \n",
    "class MyDatasetSplit():\n",
    "    def __init__(self, dataset, split='train'):\n",
    "        self.split = split\n",
    "        self.path_list = []\n",
    "        # collect list of files relevant to split.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "    def get_data(self, idx):\n",
    "        path = self.path_list[idx]\n",
    "        points, features, labels = read_pc(path)\n",
    "        return {'point': points, 'feat': features, 'label': labels}\n",
    "\n",
    "    def get_attr(self, idx):\n",
    "        path = self.path_list[idx]\n",
    "        name = path.split('/')[-1]\n",
    "        return {'name': name, 'path': path, 'split': self.split}\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d569c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
